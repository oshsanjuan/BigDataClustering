{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66376930-190b-4caf-915c-27c284d22ff0",
   "metadata": {},
   "source": [
    "### Necessary packages to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6430aa-5a3a-4c73-b182-b9843142a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import boto3\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "from pyspark.ml.functions import array_to_vector\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc187e00-c977-46dd-95d5-8f8c4b2abfa6",
   "metadata": {},
   "source": [
    "### Initialize the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c795ae-f734-478c-8df5-7b078280d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local[*]')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca287759-9cb0-4977-b88d-ce89f0b3976a",
   "metadata": {},
   "source": [
    "### Extraction of file paths of all images\n",
    "- This is a necessary step because we have to read/open the images one at a time to be able to feed it to a feature extraction model. More of it to be discussed in the following steps\n",
    "- *replace placeholders for* `YOUR_ACCESS_KEY` *and* `YOUR_SECRET_KEY` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a27da-e8b7-4b10-aa5d-08e34a589960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=\"YOUR_ACCESS_KEY\",  # Encode access key\n",
    "    aws_secret_access_key=\"YOUR_SECRET_KEY\",  # Encode secret key\n",
    ")\n",
    "\n",
    "# Bucket and prefix for the filepath of the images in the s3 bucket\n",
    "bucket = \"bdcc2024-cpt5-finalproject\"\n",
    "prefix = \"cats_550k\"\n",
    "\n",
    "# Create a paginator to handle multiple pages of results\n",
    "paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "\n",
    "# Initialize an empty list to hold the image paths\n",
    "image_paths = []\n",
    "\n",
    "# Iterate through all pages of results\n",
    "for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "    # Append paths of image files to the list\n",
    "    for item in page.get(\"Contents\", []):\n",
    "        if item[\"Key\"].lower().endswith((\".png\", \".jpg\", \".jpeg\",\n",
    "                                         \".bmp\", \".gif\")):\n",
    "            image_paths.append(f\"s3a://{bucket}/{item['Key']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75ab1b-425d-4933-9413-9cd9735dad8e",
   "metadata": {},
   "source": [
    "### Creation of a Feature Extraction Function\n",
    "- A function is defined to access the images in the s3 bucket and then convert it to an array then subjected to a convolutional neural network to extract the features it generates.\n",
    "- The function should be registered in the `pyspark.sql.functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779adf0-91dc-4029-96c7-8e1bcec37456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "# In this case, the team used VGG16.\n",
    "model = VGG16(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "def extract_features_from_path(image_path, model):\n",
    "    try:\n",
    "        # Extract bucket name and key\n",
    "        bucket, key = image_path.replace(\"s3a://\", \"\").split(\"/\", 1)\n",
    "        \n",
    "        # Fetch the image using boto3\n",
    "        s3 = boto3.client('s3')\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "        image_bytes = response['Body'].read()\n",
    "\n",
    "        # Load the image directly from bytes\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        \n",
    "        # Convert image to RGB if it's not already\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Resize the image\n",
    "        image = image.resize((150, 150))\n",
    "        \n",
    "        # Convert image to array and preprocess\n",
    "        img_array = tf.keras.utils.img_to_array(image)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        \n",
    "        # Extract features using the model\n",
    "        features = model.predict(img_array).flatten()\n",
    "        return features.tolist()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log the error for debugging purposes\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        \n",
    "        # Return a default value, e.g., an empty list or a list with zeros\n",
    "        return [0.0] * 512  # 512 is the feature vector length from VGG16\n",
    "\n",
    "# Register the UDF for spark usage\n",
    "extract_features_udf = udf(extract_features_from_path, ArrayType(DoubleType()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b8b42-b521-4c7a-848a-c65abf15a828",
   "metadata": {},
   "source": [
    "### Save extracted features as a spark dataframe for persistence.\n",
    "- The saved files can be accessed by multiple members to work on in parallel.\n",
    "- The team suggests that this step be done in batches in case unexpected crashes or errors occur. \n",
    "- It is highly advised to keep a tracker on the progress of saving the files created. In this procedure, the team printed string messages as well as created text files that can be used to trace the progress of the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56dade7-8ce6-4d6a-bdef-c0122f6fbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk size to be saved at a time.\n",
    "paths_per_file = 1_000\n",
    "\n",
    "# Calculate the number of files needed\n",
    "num_files = len(image_paths) // paths_per_file + (\n",
    "    1 if len(image_paths) % paths_per_file > 0 else 0\n",
    ")\n",
    "\n",
    "# Trace back precaution.\n",
    "# Define the directory relative to the current working directory\n",
    "directory = os.path.join(os.getcwd(), \"checkpoint\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(num_files):  # Index `num_files` accordingly if crashes occur.\n",
    "    # create chunks of the image_paths\n",
    "    chunk_paths = image_paths[i * paths_per_file : (i + 1) * paths_per_file]\n",
    "    image_df = (\n",
    "        spark.createDataFrame([Row(image_path=path) for path in chunk_paths])\n",
    "    )\n",
    "    features_df = image_df.select(\n",
    "        \"image_path\",\n",
    "        array_to_vector(extract_features_udf(\"image_path\")).alias(\"features\"),\n",
    "    )\n",
    "\n",
    "    # write to the s3 bucket\n",
    "    features_df.write.mode(\"append\").parquet(\n",
    "        \"s3a://bdcc2024-cpt5-finalproject/cats_550k_features-parquet\"\n",
    "    )\n",
    "\n",
    "    # create  \".txt\" file to serve as checkpoints\n",
    "    file_path = os.path.join(directory, f\"Done with Chunk{i+1}.txt\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(f\"Checkpoint for chunk {i+1}\")\n",
    "\n",
    "    # printing checkpoints\n",
    "    print(f\"Done with Chunk {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8f684-5c69-47a7-be34-cf7038068f39",
   "metadata": {},
   "source": [
    "#### Congratulations\n",
    "You now have extracted the features of the images that will be used in clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcadd421-6624-4262-a868-b8e053355fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
